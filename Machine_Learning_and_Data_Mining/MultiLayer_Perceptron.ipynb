{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# !pip show tensorflow\n",
    "# !pip show keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.squeeze(np.load('src/smiley_X.npy'))\n",
    "y = np.load('src/smiley_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "(144, 9, 9)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Classification Model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Train Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n       0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sigmoid is used for the output layer and there's only 1 output node."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[9, 9]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=[keras.metrics.binary_accuracy])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barth\\Desktop\\HWU\\Data Mining and Machine Learning\\Git\\F21DL-Machine-Learning-Group-Work\\venv\\lib\\site-packages\\keras\\backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step - loss: 0.6873 - binary_accuracy: 0.5217\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6838 - binary_accuracy: 0.5304\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6801 - binary_accuracy: 0.5304\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6766 - binary_accuracy: 0.5304\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6728 - binary_accuracy: 0.5391\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6694 - binary_accuracy: 0.5304\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6662 - binary_accuracy: 0.5478\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6627 - binary_accuracy: 0.5565\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6593 - binary_accuracy: 0.5913\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6557 - binary_accuracy: 0.6087\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1937b338e20>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metrics\n",
    "Loss and Accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000001937AE37250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6508 - binary_accuracy: 0.7586\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6508159041404724, 0.7586206793785095]"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.62068966, 0.        ],\n       [0.37931034, 0.        ]])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict\n",
    "y_prediction = np.argmax(model.predict(x_test), axis=1)\n",
    "\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "confusion_matrix(y_test, y_prediction , normalize='pred')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ðŸ”· Q: I don't get why it's 0 here for the confusion matrix?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Categorical Classification Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### One-hot encode y and new test train split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "y = keras.utils.to_categorical(y-1, num_classes = 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 2ms/step - loss: 0.7586 - categorical_accuracy: 0.5130 - true_positives_3: 59.0000 - false_positives_3: 56.0000 - true_negatives_3: 59.0000 - false_negatives_3: 56.0000 - precision_3: 0.5130 - recall_3: 0.5130\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7506 - categorical_accuracy: 0.5130 - true_positives_3: 59.0000 - false_positives_3: 56.0000 - true_negatives_3: 59.0000 - false_negatives_3: 56.0000 - precision_3: 0.5130 - recall_3: 0.5130\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7439 - categorical_accuracy: 0.5130 - true_positives_3: 59.0000 - false_positives_3: 56.0000 - true_negatives_3: 59.0000 - false_negatives_3: 56.0000 - precision_3: 0.5130 - recall_3: 0.5130\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7365 - categorical_accuracy: 0.5130 - true_positives_3: 59.0000 - false_positives_3: 56.0000 - true_negatives_3: 59.0000 - false_negatives_3: 56.0000 - precision_3: 0.5130 - recall_3: 0.5130\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7308 - categorical_accuracy: 0.5043 - true_positives_3: 58.0000 - false_positives_3: 57.0000 - true_negatives_3: 58.0000 - false_negatives_3: 57.0000 - precision_3: 0.5043 - recall_3: 0.5043\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7248 - categorical_accuracy: 0.5130 - true_positives_3: 59.0000 - false_positives_3: 56.0000 - true_negatives_3: 59.0000 - false_negatives_3: 56.0000 - precision_3: 0.5130 - recall_3: 0.5130\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7186 - categorical_accuracy: 0.5130 - true_positives_3: 59.0000 - false_positives_3: 56.0000 - true_negatives_3: 59.0000 - false_negatives_3: 56.0000 - precision_3: 0.5130 - recall_3: 0.5130\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7134 - categorical_accuracy: 0.5130 - true_positives_3: 59.0000 - false_positives_3: 56.0000 - true_negatives_3: 59.0000 - false_negatives_3: 56.0000 - precision_3: 0.5130 - recall_3: 0.5130\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7080 - categorical_accuracy: 0.5130 - true_positives_3: 59.0000 - false_positives_3: 56.0000 - true_negatives_3: 59.0000 - false_negatives_3: 56.0000 - precision_3: 0.5130 - recall_3: 0.5130\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7031 - categorical_accuracy: 0.5043 - true_positives_3: 58.0000 - false_positives_3: 57.0000 - true_negatives_3: 58.0000 - false_negatives_3: 57.0000 - precision_3: 0.5043 - recall_3: 0.5043\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x193738ef790>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[9, 9]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "              metrics=[keras.metrics.categorical_accuracy, keras.metrics.TruePositives(), keras.metrics.FalsePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalseNegatives(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "# The metrics are for the train data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metrics\n",
    "Loss, Accuracy, TP, FP, TN, FN, Precision, Recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 408ms/step - loss: 0.7709 - categorical_accuracy: 0.3448 - true_positives_3: 10.0000 - false_positives_3: 19.0000 - true_negatives_3: 10.0000 - false_negatives_3: 19.0000 - precision_3: 0.3448 - recall_3: 0.3448\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.7708953619003296,\n 0.3448275923728943,\n 10.0,\n 19.0,\n 10.0,\n 19.0,\n 0.3448275923728943,\n 0.3448275923728943]"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment With Various Parameters That Control The Learning\n",
    "Configuration Suite"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "layers_list = [[64,16,2],[32,8,2],[16,4,2],[5,3,2]]\n",
    "Î·_list = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "epochs = [3, 5, 10, 50, 100]\n",
    "optimisations = [keras.optimizers.SGD, keras.optimizers.RMSprop, keras.optimizers.Adam, keras.optimizers.Nadam]\n",
    "activations = [\"sigmoid\", \"tanh\", \"relu\", \"LeakyReLU\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "run_config_suit = False\n",
    "file_name = \"df_ML_P.pkl\"\n",
    "\n",
    "if run_config_suit:\n",
    "    start = time.time()\n",
    "    list_of_results = []\n",
    "    for layer in layers_list:\n",
    "        for opt in optimisations:\n",
    "            for Î· in Î·_list:\n",
    "                for act in activations:\n",
    "                    print(\"\\n####################################################################################\")\n",
    "                    print(\"Layers      Eta Act.    <Optimisation>\")\n",
    "                    print(f\"{layer} {Î·} {act} {opt}\")\n",
    "                    print(\"Epoch: [Loss, Accuracy, TP, FP, TN, FN, Precision, Recall]\")\n",
    "                    for epoch in epochs:\n",
    "                        model = keras.models.Sequential([\n",
    "                            keras.layers.Flatten(input_shape=[9, 9]),\n",
    "                            keras.layers.Dense(layer[0], activation=act),\n",
    "                            keras.layers.Dense(layer[1], activation=act),\n",
    "                            keras.layers.Dense(2, activation=\"softmax\")\n",
    "                        ])\n",
    "                        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                      optimizer=opt(learning_rate=Î·),\n",
    "                                      metrics=[keras.metrics.categorical_accuracy, keras.metrics.TruePositives(), keras.metrics.FalsePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalseNegatives(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "                        model.fit(x_train, y_train, epochs=epoch, verbose= 0)\n",
    "                        result = model.evaluate(x_test, y_test, verbose= 0)\n",
    "                        config = [layer, opt, Î·, act, epoch]\n",
    "                        list_of_results.append(result + config)\n",
    "                        print(f\"\\t{epoch}: {result}\")\n",
    "\n",
    "    print(\"\\n\\n############## DONE\")\n",
    "    print(time.time() - start)\n",
    "\n",
    "    labels = [\"Loss\", \"Accuracy\", \"TP\", \"FP\", \"TN\", \"FN\", \"Precision\", \"Recall\", \"Layers\", \"optimiser\", \"Î·\", \"activation\", \"epoch\"]\n",
    "    df = pd.DataFrame(data = list_of_results, columns=labels)\n",
    "    df.to_pickle(file_name)\n",
    "\n",
    "else:\n",
    "    df = pd.read_pickle(file_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It took 4414.6s (~1.2hrs) to run the configuration suite on G Drive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall 1600 model was generated with different hyperparameters.\n",
    "* layers_list = 4 variation\n",
    "* Î·_list = 5 variation\n",
    "* epochs = 5 variation\n",
    "* optimisations = 4 variation\n",
    "* activations = 4 variation\n",
    "\n",
    "4 Ã— 5 Ã— 5 Ã— 4 Ã— 4 = 1600.\n",
    "\n",
    "The dataframe holds the metrics for each configuration and the configuration details."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "          Loss  Accuracy    TP    FP    TN    FN  Precision    Recall  \\\n0     0.725694  0.379310  11.0  18.0  11.0  18.0   0.379310  0.379310   \n1     0.708019  0.379310  11.0  18.0  11.0  18.0   0.379310  0.379310   \n2     0.682639  0.413793  12.0  17.0  12.0  17.0   0.413793  0.413793   \n3     0.589108  0.965517  28.0   1.0  28.0   1.0   0.965517  0.965517   \n4     0.084866  1.000000  29.0   0.0  29.0   0.0   1.000000  1.000000   \n...        ...       ...   ...   ...   ...   ...        ...       ...   \n1595  0.562120  0.758621  22.0   7.0  22.0   7.0   0.758621  0.758621   \n1596  0.656760  0.724138  21.0   8.0  21.0   8.0   0.724138  0.724138   \n1597  0.812644  0.275862   8.0  21.0   8.0  21.0   0.275862  0.275862   \n1598  0.824477  0.620690  18.0  11.0  18.0  11.0   0.620690  0.620690   \n1599  0.751345  0.344828  10.0  19.0  10.0  19.0   0.344828  0.344828   \n\n           Layers                                          optimiser        Î·  \\\n0     [64, 16, 2]  <class 'keras.optimizers.optimizer_v2.gradient...  0.10000   \n1     [64, 16, 2]  <class 'keras.optimizers.optimizer_v2.gradient...  0.10000   \n2     [64, 16, 2]  <class 'keras.optimizers.optimizer_v2.gradient...  0.10000   \n3     [64, 16, 2]  <class 'keras.optimizers.optimizer_v2.gradient...  0.10000   \n4     [64, 16, 2]  <class 'keras.optimizers.optimizer_v2.gradient...  0.10000   \n...           ...                                                ...      ...   \n1595    [5, 3, 2]  <class 'keras.optimizers.optimizer_v2.nadam.Na...  0.00001   \n1596    [5, 3, 2]  <class 'keras.optimizers.optimizer_v2.nadam.Na...  0.00001   \n1597    [5, 3, 2]  <class 'keras.optimizers.optimizer_v2.nadam.Na...  0.00001   \n1598    [5, 3, 2]  <class 'keras.optimizers.optimizer_v2.nadam.Na...  0.00001   \n1599    [5, 3, 2]  <class 'keras.optimizers.optimizer_v2.nadam.Na...  0.00001   \n\n     activation  epoch  \n0       sigmoid      3  \n1       sigmoid      5  \n2       sigmoid     10  \n3       sigmoid     50  \n4       sigmoid    100  \n...         ...    ...  \n1595  LeakyReLU      3  \n1596  LeakyReLU      5  \n1597  LeakyReLU     10  \n1598  LeakyReLU     50  \n1599  LeakyReLU    100  \n\n[1600 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n      <th>TP</th>\n      <th>FP</th>\n      <th>TN</th>\n      <th>FN</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Layers</th>\n      <th>optimiser</th>\n      <th>Î·</th>\n      <th>activation</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.725694</td>\n      <td>0.379310</td>\n      <td>11.0</td>\n      <td>18.0</td>\n      <td>11.0</td>\n      <td>18.0</td>\n      <td>0.379310</td>\n      <td>0.379310</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.gradient...</td>\n      <td>0.10000</td>\n      <td>sigmoid</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.708019</td>\n      <td>0.379310</td>\n      <td>11.0</td>\n      <td>18.0</td>\n      <td>11.0</td>\n      <td>18.0</td>\n      <td>0.379310</td>\n      <td>0.379310</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.gradient...</td>\n      <td>0.10000</td>\n      <td>sigmoid</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.682639</td>\n      <td>0.413793</td>\n      <td>12.0</td>\n      <td>17.0</td>\n      <td>12.0</td>\n      <td>17.0</td>\n      <td>0.413793</td>\n      <td>0.413793</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.gradient...</td>\n      <td>0.10000</td>\n      <td>sigmoid</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.589108</td>\n      <td>0.965517</td>\n      <td>28.0</td>\n      <td>1.0</td>\n      <td>28.0</td>\n      <td>1.0</td>\n      <td>0.965517</td>\n      <td>0.965517</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.gradient...</td>\n      <td>0.10000</td>\n      <td>sigmoid</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.084866</td>\n      <td>1.000000</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.gradient...</td>\n      <td>0.10000</td>\n      <td>sigmoid</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>0.562120</td>\n      <td>0.758621</td>\n      <td>22.0</td>\n      <td>7.0</td>\n      <td>22.0</td>\n      <td>7.0</td>\n      <td>0.758621</td>\n      <td>0.758621</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n      <td>0.00001</td>\n      <td>LeakyReLU</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>0.656760</td>\n      <td>0.724138</td>\n      <td>21.0</td>\n      <td>8.0</td>\n      <td>21.0</td>\n      <td>8.0</td>\n      <td>0.724138</td>\n      <td>0.724138</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n      <td>0.00001</td>\n      <td>LeakyReLU</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>0.812644</td>\n      <td>0.275862</td>\n      <td>8.0</td>\n      <td>21.0</td>\n      <td>8.0</td>\n      <td>21.0</td>\n      <td>0.275862</td>\n      <td>0.275862</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n      <td>0.00001</td>\n      <td>LeakyReLU</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>0.824477</td>\n      <td>0.620690</td>\n      <td>18.0</td>\n      <td>11.0</td>\n      <td>18.0</td>\n      <td>11.0</td>\n      <td>0.620690</td>\n      <td>0.620690</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n      <td>0.00001</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1599</th>\n      <td>0.751345</td>\n      <td>0.344828</td>\n      <td>10.0</td>\n      <td>19.0</td>\n      <td>10.0</td>\n      <td>19.0</td>\n      <td>0.344828</td>\n      <td>0.344828</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n      <td>0.00001</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n<p>1600 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter for 0 loss\n",
    "- 5  epochs\n",
    "- 10 epochs\n",
    "\n",
    "The lower the loss the better so 0 is the most desirable. Same is true for epochs. The fewer epochs it has to run the better it is."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "      Loss  Accuracy    TP   FP    TN   FN  Precision  Recall       Layers  \\\n104    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n109    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n114    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n118    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n119    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n124    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n129    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n134    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n139    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n211    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n214    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n216    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n217    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n218    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n504    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [32, 8, 2]   \n509    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [32, 8, 2]   \n514    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [32, 8, 2]   \n519    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [32, 8, 2]   \n529    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [32, 8, 2]   \n534    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [32, 8, 2]   \n539    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [32, 8, 2]   \n618    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [32, 8, 2]   \n619    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [32, 8, 2]   \n904    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n909    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n914    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n919    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n929    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n934    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n939    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n1013   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n1017   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n1018   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n1019   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n1304   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0    [5, 3, 2]   \n1309   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0    [5, 3, 2]   \n1314   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0    [5, 3, 2]   \n1319   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0    [5, 3, 2]   \n1334   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0    [5, 3, 2]   \n1339   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0    [5, 3, 2]   \n1414   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0    [5, 3, 2]   \n1418   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0    [5, 3, 2]   \n1419   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0    [5, 3, 2]   \n\n                                              optimiser     Î· activation  \\\n104   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10    sigmoid   \n109   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10       tanh   \n114   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10       relu   \n118   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10  LeakyReLU   \n119   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10  LeakyReLU   \n124   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01    sigmoid   \n129   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01       tanh   \n134   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01       relu   \n139   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01  LeakyReLU   \n211   <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10       relu   \n214   <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10       relu   \n216   <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10  LeakyReLU   \n217   <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10  LeakyReLU   \n218   <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10  LeakyReLU   \n504   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10    sigmoid   \n509   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10       tanh   \n514   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10       relu   \n519   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10  LeakyReLU   \n529   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01       tanh   \n534   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01       relu   \n539   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01  LeakyReLU   \n618   <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10  LeakyReLU   \n619   <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10  LeakyReLU   \n904   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10    sigmoid   \n909   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10       tanh   \n914   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10       relu   \n919   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10  LeakyReLU   \n929   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01       tanh   \n934   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01       relu   \n939   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01  LeakyReLU   \n1013  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10       relu   \n1017  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10  LeakyReLU   \n1018  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10  LeakyReLU   \n1019  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10  LeakyReLU   \n1304  <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10    sigmoid   \n1309  <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10       tanh   \n1314  <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10       relu   \n1319  <class 'keras.optimizers.optimizer_v2.rmsprop....  0.10  LeakyReLU   \n1334  <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01       relu   \n1339  <class 'keras.optimizers.optimizer_v2.rmsprop....  0.01  LeakyReLU   \n1414  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10       relu   \n1418  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10  LeakyReLU   \n1419  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.10  LeakyReLU   \n\n      epoch  \n104     100  \n109     100  \n114     100  \n118      50  \n119     100  \n124     100  \n129     100  \n134     100  \n139     100  \n211       5  \n214     100  \n216       5  \n217      10  \n218      50  \n504     100  \n509     100  \n514     100  \n519     100  \n529     100  \n534     100  \n539     100  \n618      50  \n619     100  \n904     100  \n909     100  \n914     100  \n919     100  \n929     100  \n934     100  \n939     100  \n1013     50  \n1017     10  \n1018     50  \n1019    100  \n1304    100  \n1309    100  \n1314    100  \n1319    100  \n1334    100  \n1339    100  \n1414    100  \n1418     50  \n1419    100  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n      <th>TP</th>\n      <th>FP</th>\n      <th>TN</th>\n      <th>FN</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Layers</th>\n      <th>optimiser</th>\n      <th>Î·</th>\n      <th>activation</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>104</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>sigmoid</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>tanh</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>relu</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>sigmoid</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>tanh</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>relu</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>211</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>relu</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>relu</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>218</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[32, 8, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>sigmoid</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[32, 8, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>tanh</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>514</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[32, 8, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>relu</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>519</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[32, 8, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>529</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[32, 8, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>tanh</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>534</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[32, 8, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>relu</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>539</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[32, 8, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>618</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[32, 8, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>619</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[32, 8, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>904</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>sigmoid</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>909</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>tanh</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>relu</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>tanh</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>934</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>relu</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1013</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>relu</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1017</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1018</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1019</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1304</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>sigmoid</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1309</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>tanh</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1314</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>relu</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1319</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1334</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>relu</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1339</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.01</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1414</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>relu</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1418</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1419</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.10</td>\n      <td>LeakyReLU</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Loss == 0 ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overall Best:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barth\\AppData\\Local\\Temp\\ipykernel_6988\\3542774355.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df.Loss == 0 ][df.epoch == 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Loss  Accuracy    TP   FP    TN   FN  Precision  Recall       Layers  \\\n211   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n216   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n\n                                             optimiser    Î· activation  epoch  \n211  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.1       relu      5  \n216  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.1  LeakyReLU      5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n      <th>TP</th>\n      <th>FP</th>\n      <th>TN</th>\n      <th>FN</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Layers</th>\n      <th>optimiser</th>\n      <th>Î·</th>\n      <th>activation</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>211</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.1</td>\n      <td>relu</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.1</td>\n      <td>LeakyReLU</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Loss == 0 ][df.epoch == 5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Second Best:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barth\\AppData\\Local\\Temp\\ipykernel_6988\\181343716.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df.Loss == 0 ][df.epoch == 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Loss  Accuracy    TP   FP    TN   FN  Precision  Recall       Layers  \\\n217    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n1017   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n\n                                              optimiser    Î· activation  epoch  \n217   <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.1  LeakyReLU     10  \n1017  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.1  LeakyReLU     10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n      <th>TP</th>\n      <th>FP</th>\n      <th>TN</th>\n      <th>FN</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Layers</th>\n      <th>optimiser</th>\n      <th>Î·</th>\n      <th>activation</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>217</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.1</td>\n      <td>LeakyReLU</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1017</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.1</td>\n      <td>LeakyReLU</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Loss == 0 ][df.epoch == 10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Third:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barth\\AppData\\Local\\Temp\\ipykernel_6988\\1342443713.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df.Loss == 0 ][df.epoch == 50]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Loss  Accuracy    TP   FP    TN   FN  Precision  Recall       Layers  \\\n118    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n218    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0  [64, 16, 2]   \n618    0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [32, 8, 2]   \n1013   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n1018   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0   [16, 4, 2]   \n1418   0.0       1.0  29.0  0.0  29.0  0.0        1.0     1.0    [5, 3, 2]   \n\n                                              optimiser    Î· activation  epoch  \n118   <class 'keras.optimizers.optimizer_v2.rmsprop....  0.1  LeakyReLU     50  \n218   <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.1  LeakyReLU     50  \n618   <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.1  LeakyReLU     50  \n1013  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.1       relu     50  \n1018  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.1  LeakyReLU     50  \n1418  <class 'keras.optimizers.optimizer_v2.adam.Adam'>  0.1  LeakyReLU     50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n      <th>TP</th>\n      <th>FP</th>\n      <th>TN</th>\n      <th>FN</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Layers</th>\n      <th>optimiser</th>\n      <th>Î·</th>\n      <th>activation</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>118</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.rmsprop....</td>\n      <td>0.1</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>218</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[64, 16, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.1</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>618</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[32, 8, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.1</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1013</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.1</td>\n      <td>relu</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1018</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[16, 4, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.1</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1418</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>[5, 3, 2]</td>\n      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n      <td>0.1</td>\n      <td>LeakyReLU</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Loss == 0 ][df.epoch == 50]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion:\n",
    "The best configuration (for epochs below 51 and with 0 loss):\n",
    "- __Nodes Per Layers__: `[64, 16, 2]`. This was the most frequent out of the best configurations. It's notable that there was a configuration for `[5, 3, 2]` that reached 0 loss with 50 epochs. There's only a very few nodes in this setting, however, it did reach 0.\n",
    "- __Optimiser__: `Adam`. This was the most frequent among the best configurations. `RMSprop` was the only other optimiser function that appeared.  `Nadam` and `SGD` didn't reach 0 within 50 epochs.\n",
    "- __Î·__: `0.1` was the only one to appear. There were a few cases of `0.01` for 100 epochs.\n",
    "- __Activation Function__ is either `LeakyReLU` or `ReLU`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "layers_list = [[64,16,2],[32,8,2],[16,4,2]]\n",
    "Î·_list = [0.1, 0.01, 0.001]\n",
    "epochs = [3, 5, 10, 50]\n",
    "optimisations = [keras.optimizers.SGD, keras.optimizers.RMSprop, keras.optimizers.Adam, keras.optimizers.Nadam]\n",
    "activations = [\"sigmoid\", \"tanh\", \"relu\", \"LeakyReLU\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'df_ML_P_2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [91], line 76\u001B[0m\n\u001B[0;32m     73\u001B[0m     dfcv\u001B[38;5;241m.\u001B[39mto_pickle(file_name)\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 76\u001B[0m     dfcv \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_pickle(file_name)\n",
      "File \u001B[1;32m~\\Desktop\\HWU\\Data Mining and Machine Learning\\Git\\F21DL-Machine-Learning-Group-Work\\venv\\lib\\site-packages\\pandas\\io\\pickle.py:190\u001B[0m, in \u001B[0;36mread_pickle\u001B[1;34m(filepath_or_buffer, compression, storage_options)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001B[39;00m\n\u001B[0;32m    126\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;124;03m4    4    9\u001B[39;00m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    189\u001B[0m excs_to_catch \u001B[38;5;241m=\u001B[39m (\u001B[38;5;167;01mAttributeError\u001B[39;00m, \u001B[38;5;167;01mImportError\u001B[39;00m, \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m)\n\u001B[1;32m--> 190\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[0;32m    197\u001B[0m \n\u001B[0;32m    198\u001B[0m     \u001B[38;5;66;03m# 1) try standard library Pickle\u001B[39;00m\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001B[39;00m\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001B[39;00m\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    203\u001B[0m         \u001B[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001B[39;00m\n\u001B[0;32m    204\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Desktop\\HWU\\Data Mining and Machine Learning\\Git\\F21DL-Machine-Learning-Group-Work\\venv\\lib\\site-packages\\pandas\\io\\common.py:866\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    857\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    858\u001B[0m             handle,\n\u001B[0;32m    859\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    862\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    863\u001B[0m         )\n\u001B[0;32m    864\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    865\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 866\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    867\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    869\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'df2_lab10.pkl'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "run_config_suit = False\n",
    "file_name = \"df2_lab10.pkl\"\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "if run_config_suit:\n",
    "    start = time.time()\n",
    "    list_of_results = []\n",
    "    list_of_crossedevaluated = []\n",
    "    for layer in layers_list:\n",
    "        for opt in optimisations:\n",
    "            for Î· in Î·_list:\n",
    "                for act in activations:\n",
    "                    print(\"\\n####################################################################################\")\n",
    "                    print(\"Layers      Eta Act.    <Optimisation>\")\n",
    "                    print(f\"{layer} {Î·} {act} {opt}\")\n",
    "                    print(\"Epoch: [Loss, Accuracy, TP, FP, TN, FN, Precision, Recall]\")\n",
    "                    for epoch in epochs:\n",
    "                        model = keras.models.Sequential([\n",
    "                            keras.layers.Flatten(input_shape=[9, 9]),\n",
    "                            keras.layers.Dense(layer[0], activation=act),\n",
    "                            keras.layers.Dense(layer[1], activation=act),\n",
    "                            keras.layers.Dense(2, activation=\"softmax\")\n",
    "                        ])\n",
    "                        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                      optimizer=opt(learning_rate=Î·),\n",
    "                                      metrics=[keras.metrics.categorical_accuracy, keras.metrics.TruePositives(), keras.metrics.FalsePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalseNegatives(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "                        for train, test in kf.split(X):\n",
    "                            model.fit(X[train],y[train], epochs=epoch, verbose= 0)\n",
    "                            result = model.evaluate(X[test],y[test], verbose= 0)\n",
    "                            list_of_crossedevaluated.append(result)\n",
    "\n",
    "                        config = [layer, opt, Î·, act, epoch]\n",
    "\n",
    "                        loss = 0\n",
    "                        acc = 0\n",
    "                        TP = 0\n",
    "                        FP = 0\n",
    "                        TN = 0\n",
    "                        FN = 0\n",
    "                        Precision = 0\n",
    "                        Recall = 0\n",
    "                        for i in list_of_crossedevaluated:\n",
    "                            loss += i[0]\n",
    "                            acc += i[1]\n",
    "                            TP += i[2]\n",
    "                            FP += i[3]\n",
    "                            TN += i[4]\n",
    "                            FN += i[5]\n",
    "                            Precision += i[6]\n",
    "                            Recall += i[7]\n",
    "                        result10 = [loss,acc,TP,FP,TN,FN,Precision,Recall]\n",
    "                        result = []\n",
    "                        for i in range(2):\n",
    "                            result.append(result10[i]/10)\n",
    "                        result.append(TP)\n",
    "                        result.append(FP)\n",
    "                        result.append(TN)\n",
    "                        result.append(FN)\n",
    "                        for i in range(6,8):\n",
    "                            result.append(result10[i]/10)\n",
    "                        list_of_results.append(result + config)\n",
    "                        list_of_crossedevaluated.clear()\n",
    "                        print(f\"\\t{epoch}: {result}\")\n",
    "\n",
    "    print(\"\\n\\n############## DONE\")\n",
    "    print(time.time() - start)\n",
    "\n",
    "    labels = [\"Loss\", \"Accuracy\", \"TP\", \"FP\", \"TN\", \"FN\", \"Precision\", \"Recall\", \"Layers\", \"optimiser\", \"Î·\", \"activation\", \"epoch\"]\n",
    "    dfcv = pd.DataFrame(data = list_of_results, columns=labels)\n",
    "    dfcv.to_pickle(file_name)\n",
    "\n",
    "else:\n",
    "    dfcv = pd.read_pickle(file_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It took 1998.28s (~33.3mins) to run this"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall 576 models were generated with different hyperparameters.\n",
    "I've reduced the number of hyperparameters explored to reduce computation time.\n",
    "* layers_list = 3 variation\n",
    "* Î·_list = 3 variation\n",
    "* epochs = 3 variation\n",
    "* optimisations = 4 variation\n",
    "* activations = 4 variation\n",
    "\n",
    "3 Ã— 3 Ã— 3 Ã— 4 Ã— 4 = 432.\n",
    "\n",
    "The dataframe holds the metrics for each configuration and the configuration details."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfcv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter for 0 loss\n",
    "- 5  epochs\n",
    "- 10 epochs\n",
    "\n",
    "The lower the loss the better so 0 is the most desirable. Same is true for epochs. The fewer epochs it has to run the better it is."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfcv[dfcv.Loss == 0 ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overall Best:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfcv[dfcv.Loss == 0 ][dfcv.epoch == 5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Second Best:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfcv[dfcv.Loss == 0 ][dfcv.epoch == 10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Third:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfcv[dfcv.Loss == 0 ][dfcv.epoch == 50]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion:\n",
    "The best configuration (for epochs below 51 and with 0 loss):\n",
    "- __Nodes Per Layers__: `[64, 16, 2]`. This was the most frequent out of the best configurations. It's notable that there was a configuration for `[5, 3, 2]` that reached 0 loss with 50 epochs. There's only a very few nodes in this setting, however, it did reach 0.\n",
    "- __Optimiser__: `Adam`. This was the most frequent among the best configurations. `RMSprop` was the only other optimiser function that appeared.  `Nadam` and `SGD` didn't reach 0 within 50 epochs.\n",
    "- __Î·__: `0.1` was the only one to appear. There were a few cases of `0.01` for 100 epochs.\n",
    "- __Activation Function__ is either `LeakyReLU` or `ReLU`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classifier over-fitting experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Classifier 1\n",
    "#First train test data set with a 0.2 split\n",
    "split1 = 0.2\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=split1)\n",
    "\n",
    "#I'm not sure if we need to keep the first train set in the other classifier and only add more data coming from the train set to the test set or if\n",
    "#we move the data from the train test to the test set and delete it from the train set, we've used the second solution in the rest of the lab\n",
    "#Classifier 2\n",
    "#Here we move 30% of the previous train set into the data set\n",
    "split2 = split1 + (1-split1) * 0.3\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=split2)\n",
    "\n",
    "#Classifier 3\n",
    "#Here we move 60% of the previous train set into the data set\n",
    "split3 = split1 + (1-split1) * 0.3\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=split3)\n",
    "\n",
    "#List to store the evaluations\n",
    "list_of_results_overfitting = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Evaluating our first classifier on the test set\n",
    "model = keras.models.Sequential([\n",
    "                            keras.layers.Flatten(input_shape=[9, 9]),\n",
    "                            keras.layers.Dense(64, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(16, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(2, activation=\"softmax\")\n",
    "                        ])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                      optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "                                      metrics=[keras.metrics.categorical_accuracy, keras.metrics.TruePositives(), keras.metrics.FalsePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalseNegatives(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.fit(X_train1,y_train1, epochs = 5)\n",
    "resulttest1 = model.evaluate(X_test1,y_test1)\n",
    "list_of_results_overfitting.append(resulttest1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Evaluating our first classifier on the train set\n",
    "model = keras.models.Sequential([\n",
    "                            keras.layers.Flatten(input_shape=[9, 9]),\n",
    "                            keras.layers.Dense(64, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(16, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(2, activation=\"softmax\")\n",
    "                        ])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                      optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "                                      metrics=[keras.metrics.categorical_accuracy, keras.metrics.TruePositives(), keras.metrics.FalsePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalseNegatives(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.fit(X_train1,y_train1, epochs = 5)\n",
    "resulttrain1 = model.evaluate(X_train1,y_train1)\n",
    "list_of_results_overfitting.append(resulttrain1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Evaluating our second classifier on the test set\n",
    "model = keras.models.Sequential([\n",
    "                            keras.layers.Flatten(input_shape=[9, 9]),\n",
    "                            keras.layers.Dense(64, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(16, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(2, activation=\"softmax\")\n",
    "                        ])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                      optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "                                      metrics=[keras.metrics.categorical_accuracy, keras.metrics.TruePositives(), keras.metrics.FalsePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalseNegatives(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.fit(X_train2,y_train2, epochs = 5)\n",
    "resulttest2 = model.evaluate(X_test2,y_test2)\n",
    "list_of_results_overfitting.append(resulttest2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Evaluating our second classifier on the train set\n",
    "model = keras.models.Sequential([\n",
    "                            keras.layers.Flatten(input_shape=[9, 9]),\n",
    "                            keras.layers.Dense(64, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(16, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(2, activation=\"softmax\")\n",
    "                        ])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                      optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "                                      metrics=[keras.metrics.categorical_accuracy, keras.metrics.TruePositives(), keras.metrics.FalsePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalseNegatives(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.fit(X_train2,y_train2, epochs = 5)\n",
    "resulttrain2 = model.evaluate(X_train2,y_train2)\n",
    "list_of_results_overfitting.append(resulttrain2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Evaluating our third classifier on the test set\n",
    "model = keras.models.Sequential([\n",
    "                            keras.layers.Flatten(input_shape=[9, 9]),\n",
    "                            keras.layers.Dense(64, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(16, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(2, activation=\"softmax\")\n",
    "                        ])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                      optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "                                      metrics=[keras.metrics.categorical_accuracy, keras.metrics.TruePositives(), keras.metrics.FalsePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalseNegatives(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.fit(X_train3,y_train3, epochs = 5)\n",
    "resulttest3 = model.evaluate(X_test3,y_test3)\n",
    "list_of_results_overfitting.append(resulttest3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Evaluating our third classifier on the train set\n",
    "model = keras.models.Sequential([\n",
    "                            keras.layers.Flatten(input_shape=[9, 9]),\n",
    "                            keras.layers.Dense(64, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(16, activation=\"LeakyReLU\"),\n",
    "                            keras.layers.Dense(2, activation=\"softmax\")\n",
    "                        ])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                      optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "                                      metrics=[keras.metrics.categorical_accuracy, keras.metrics.TruePositives(), keras.metrics.FalsePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalseNegatives(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "model.fit(X_train3,y_train3, epochs = 5)\n",
    "resulttrain3 = model.evaluate(X_train3,y_train3)\n",
    "list_of_results_overfitting.append(resulttest3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = [\"Loss\", \"Accuracy\", \"TP\", \"FP\", \"TN\", \"FN\", \"Precision\", \"Recall\"]\n",
    "labels2 = [\"Classifier 1 test\", \"Classifier 1 train\", \"Classifier 2 test\", \"Classifier 2 train\", \"Classifier 3 test\", \"Classifier 3 train\"]\n",
    "df = pd.DataFrame(data = list_of_results_overfitting, columns=labels, index = labels2)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I can't seem to notice anything at least in the table as the results are the same for each one"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
